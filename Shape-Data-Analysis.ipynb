{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, struct\n",
    "import matplotlib as plt\n",
    "from array import array as pyarray\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from pylab import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NMNIST(dataset=\"training\", digits=range(10), path=r'E:\\Users\\Shashi\\OneDrive\\Datasets\\Shapes'):\n",
    "    \n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'Shapes_1_1_Train_Features.dat')\n",
    "        fname_lbl = os.path.join(path, 'Shapes_1_1_Train_Labels.dat')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 'Shapes_1_1_Test_Features.dat')\n",
    "        fname_lbl = os.path.join(path, 'Shapes_1_1_Test_Labels.dat')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    lbl = np.fromfile(flbl, dtype=np.uint8)\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    img = np.fromfile(fimg, dtype=np.uint8)\n",
    "    fimg.close()\n",
    "\n",
    "    size=len(lbl)\n",
    "\n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    rows=28;cols=28;\n",
    "\n",
    "    images = zeros((N, rows, cols), dtype=uint8)\n",
    "    labels = zeros((N, 1), dtype=int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectortoimg(v,show=True):\n",
    "    plt.imshow(v.reshape(28, 28),interpolation='None', cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200913f6f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path= os.path.join(os.path.curdir, 'data')\n",
    "images, labels = load_NMNIST('training', digits=[0,1,2], path=path)\n",
    "\n",
    "flatimages = list()\n",
    "for i in images:\n",
    "    flatimages.append(i.ravel())\n",
    "x_train = asarray(flatimages) # X now contains 60000 feature vectors, each of dimension 784\n",
    "y_train=labels # T contains class labels with 0->Triangle, 1->Square, 2->Pizza\n",
    "vectortoimg(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Checking multiple training vectors by plotting images.\\nBe patient:\")\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "nrows=15\n",
    "ncols=15\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        plt.subplot(nrows, ncols, row*ncols+col + 1)\n",
    "        vectortoimg(x_train[np.random.randint(len(y_train))],show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_NMNIST('testing', digits=[0,1,2], path=path)\n",
    "flatimages = list()\n",
    "for i in images:\n",
    "    flatimages.append(i.ravel())\n",
    "x_test = asarray(flatimages) # X now contains 60000 feature vectors, each of dimension 784\n",
    "y_test = labels # T contains class labels with 0->Triangle, 1->Square, 2->Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single fully-connected neural layer as encoder and as decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 3 floats -> 3 floats represents 3 classes\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's also create a separate encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Crossentropy loss, and Adadelta Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 2s - loss: 0.6655 - val_loss: 0.6215\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 2s - loss: 0.3876 - val_loss: 0.1143\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 3s - loss: 0.0504 - val_loss: 0.0225\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 2s - loss: 0.0151 - val_loss: 0.0103\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 3s - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 3s - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 3s - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 4s - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 4s - loss: 0.0022 - val_loss: 0.0020-\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 4s - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 4s - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 5s - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 3s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 2s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 3s - loss: 9.8042e-04 - val_loss: 9.3963e-04 0s - loss: 9.8330\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 3s - loss: 8.9811e-04 - val_loss: 8.6478e-04\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 3s - loss: 8.2937e-04 - val_loss: 8.0182e-04\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 3s - loss: 7.7119e-04 - val_loss: 7.4820e-04\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 3s - loss: 7.2137e-04 - val_loss: 7.0202e-04\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 3s - loss: 6.7826e-04 - val_loss: 6.6189e-04\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 4s - loss: 6.4064e-04 - val_loss: 6.2671e-04\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 3s - loss: 6.0754e-04 - val_loss: 5.9566e-04\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 3s - loss: 5.7822e-04 - val_loss: 5.6806e-04\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 3s - loss: 5.5208e-04 - val_loss: 5.4338e-04\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 3s - loss: 5.2865e-04 - val_loss: 5.2120e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20094cb1d68>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=25,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200961c42b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros((len(y_test), 2))\n",
    "for index, item in enumerate(y_test):\n",
    "    result[index] = (y_test[index], np.max(encoded_imgs[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  0.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0: 'target', 1: 'y_predict'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">y_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>3390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>3317.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_predict                                   \n",
       "           count mean  std  min  25%  50%  75%  max\n",
       "target                                             \n",
       "0.0       3390.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1.0       3293.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2.0       3317.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(df.target).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_predict</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.818971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target                                           \n",
       "             count    mean       std  min  25%  50%  75%  max\n",
       "y_predict                                                    \n",
       "0.0        10000.0  0.9927  0.818971  0.0  0.0  1.0  2.0  2.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(df.y_predict).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 5s - loss: 1.6842e-04 - val_loss: 1.7318e-04\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 4s - loss: 1.6799e-04 - val_loss: 1.7285e-04\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 5s - loss: 1.6767e-04 - val_loss: 1.7259e-04\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 6s - loss: 1.6743e-04 - val_loss: 1.7239e-04\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 7s - loss: 1.6723e-04 - val_loss: 1.7223e-04\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 7s - loss: 1.6707e-04 - val_loss: 1.7209e-04\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 6s - loss: 1.6693e-04 - val_loss: 1.7197e-04\n",
      "Epoch 8/25\n",
      "14336/60000 [======>.......................] - ETA: 4s - loss: 1.6682e-04- ETA: 5s - loss: 1.668"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=25,\n",
    "                batch_size=512,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
