{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, struct\n",
    "import matplotlib as plt\n",
    "from array import array as pyarray\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from pylab import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NMNIST(dataset=\"training\", digits=range(10), path=r'E:\\Users\\Shashi\\OneDrive\\Datasets\\Shapes'):\n",
    "    \n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'Shapes_1_1_Train_Features.dat')\n",
    "        fname_lbl = os.path.join(path, 'Shapes_1_1_Train_Labels.dat')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 'Shapes_1_1_Test_Features.dat')\n",
    "        fname_lbl = os.path.join(path, 'Shapes_1_1_Test_Labels.dat')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    lbl = np.fromfile(flbl, dtype=np.uint8)\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    img = np.fromfile(fimg, dtype=np.uint8)\n",
    "    fimg.close()\n",
    "\n",
    "    size=len(lbl)\n",
    "\n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    rows=28;cols=28;\n",
    "\n",
    "    images = zeros((N, rows, cols), dtype=uint8)\n",
    "    labels = zeros((N, 1), dtype=int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectortoimg(v,show=True):\n",
    "    plt.imshow(v.reshape(28, 28),interpolation='None', cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niR9C/Q2H4kPRU0/tVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2aac1e1750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path= os.path.join(os.path.curdir, 'data')\n",
    "images, labels = load_NMNIST('training', digits=[0,1,2], path=path)\n",
    "\n",
    "flatimages = list()\n",
    "for i in images:\n",
    "    flatimages.append(i.ravel())\n",
    "x_train = asarray(flatimages) # X now contains 60000 feature vectors, each of dimension 784\n",
    "y_train=labels # T contains class labels with 0->Triangle, 1->Square, 2->Pizza\n",
    "vectortoimg(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Checking multiple training vectors by plotting images.\\nBe patient:\")\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "nrows=15\n",
    "ncols=15\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        plt.subplot(nrows, ncols, row*ncols+col + 1)\n",
    "        vectortoimg(x_train[np.random.randint(len(y_train))],show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_NMNIST('testing', digits=[0,1,2], path=path)\n",
    "flatimages = list()\n",
    "for i in images:\n",
    "    flatimages.append(i.ravel())\n",
    "x_test = asarray(flatimages) # X now contains 60000 feature vectors, each of dimension 784\n",
    "y_test = labels # T contains class labels with 0->Triangle, 1->Square, 2->Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single fully-connected neural layer as encoder and as decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 3 floats -> 3 floats represents 3 classes\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's also create a separate encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Crossentropy loss, and Adadelta Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3944 - val_loss: 0.3004\n",
      "Epoch 2/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3133 - val_loss: 0.2874\n",
      "Epoch 3/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2984 - val_loss: 0.2719\n",
      "Epoch 4/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2820 - val_loss: 0.2514\n",
      "Epoch 5/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2726 - val_loss: 0.2387\n",
      "Epoch 6/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2658 - val_loss: 0.2278\n",
      "Epoch 7/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2613 - val_loss: 0.2210\n",
      "Epoch 8/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2580 - val_loss: 0.2169\n",
      "Epoch 9/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2546 - val_loss: 0.2132\n",
      "Epoch 10/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2508 - val_loss: 0.2097\n",
      "Epoch 11/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2466 - val_loss: 0.2055\n",
      "Epoch 12/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2421 - val_loss: 0.2027\n",
      "Epoch 13/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2373 - val_loss: 0.1990\n",
      "Epoch 14/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2324 - val_loss: 0.1954\n",
      "Epoch 15/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2276 - val_loss: 0.1925\n",
      "Epoch 16/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2228 - val_loss: 0.1883\n",
      "Epoch 17/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2181 - val_loss: 0.1837\n",
      "Epoch 18/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2136 - val_loss: 0.1808\n",
      "Epoch 19/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2094 - val_loss: 0.1773\n",
      "Epoch 20/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2053 - val_loss: 0.1738\n",
      "Epoch 21/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2014 - val_loss: 0.1705\n",
      "Epoch 22/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1977 - val_loss: 0.1671\n",
      "Epoch 23/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1942 - val_loss: 0.1642\n",
      "Epoch 24/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1909 - val_loss: 0.1610\n",
      "Epoch 25/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1877 - val_loss: 0.1579\n",
      "Epoch 26/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1847 - val_loss: 0.1554\n",
      "Epoch 27/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1819 - val_loss: 0.1527\n",
      "Epoch 28/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1792 - val_loss: 0.1506\n",
      "Epoch 29/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1767 - val_loss: 0.1485\n",
      "Epoch 30/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1743 - val_loss: 0.1464\n",
      "Epoch 31/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1720 - val_loss: 0.1448\n",
      "Epoch 32/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1699 - val_loss: 0.1435\n",
      "Epoch 33/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1679 - val_loss: 0.1416\n",
      "Epoch 34/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1661 - val_loss: 0.1407\n",
      "Epoch 35/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1644 - val_loss: 0.1393\n",
      "Epoch 36/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1628 - val_loss: 0.1382\n",
      "Epoch 37/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1612 - val_loss: 0.1369\n",
      "Epoch 38/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1598 - val_loss: 0.1358\n",
      "Epoch 39/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1585 - val_loss: 0.1351\n",
      "Epoch 40/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1573 - val_loss: 0.1341\n",
      "Epoch 41/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1561 - val_loss: 0.1329\n",
      "Epoch 42/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1550 - val_loss: 0.1327\n",
      "Epoch 43/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1540 - val_loss: 0.1318\n",
      "Epoch 44/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1530 - val_loss: 0.1315\n",
      "Epoch 45/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1521 - val_loss: 0.1311\n",
      "Epoch 46/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1513 - val_loss: 0.1302\n",
      "Epoch 47/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1505 - val_loss: 0.1293\n",
      "Epoch 48/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1498 - val_loss: 0.1293\n",
      "Epoch 49/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1491 - val_loss: 0.1282\n",
      "Epoch 50/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1485 - val_loss: 0.1284\n",
      "Epoch 51/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1478 - val_loss: 0.1279\n",
      "Epoch 52/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1473 - val_loss: 0.1278\n",
      "Epoch 53/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1467 - val_loss: 0.1272\n",
      "Epoch 54/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1462 - val_loss: 0.1267\n",
      "Epoch 55/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1458 - val_loss: 0.1266\n",
      "Epoch 56/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1453 - val_loss: 0.1262\n",
      "Epoch 57/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1449 - val_loss: 0.1257\n",
      "Epoch 58/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1445 - val_loss: 0.1254\n",
      "Epoch 59/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1441 - val_loss: 0.1252\n",
      "Epoch 60/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1437 - val_loss: 0.1254\n",
      "Epoch 61/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1434 - val_loss: 0.1243\n",
      "Epoch 62/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1430 - val_loss: 0.1247\n",
      "Epoch 63/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1427 - val_loss: 0.1245\n",
      "Epoch 64/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1424 - val_loss: 0.1248\n",
      "Epoch 65/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1421 - val_loss: 0.1243\n",
      "Epoch 66/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1418 - val_loss: 0.1238\n",
      "Epoch 67/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1415 - val_loss: 0.1237\n",
      "Epoch 68/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1413 - val_loss: 0.1237\n",
      "Epoch 69/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1410 - val_loss: 0.1241\n",
      "Epoch 70/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1407 - val_loss: 0.1231\n",
      "Epoch 71/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1405 - val_loss: 0.1235\n",
      "Epoch 72/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1402 - val_loss: 0.1231\n",
      "Epoch 73/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1400 - val_loss: 0.1224\n",
      "Epoch 74/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1398 - val_loss: 0.1231\n",
      "Epoch 75/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1395 - val_loss: 0.1233\n",
      "Epoch 76/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1393 - val_loss: 0.1230\n",
      "Epoch 77/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1391 - val_loss: 0.1225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1388 - val_loss: 0.1224\n",
      "Epoch 79/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1386 - val_loss: 0.1223\n",
      "Epoch 80/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1384 - val_loss: 0.1219\n",
      "Epoch 81/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1381 - val_loss: 0.1218\n",
      "Epoch 82/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1379 - val_loss: 0.1214\n",
      "Epoch 83/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1377 - val_loss: 0.1219\n",
      "Epoch 84/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1375 - val_loss: 0.1222\n",
      "Epoch 85/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1372 - val_loss: 0.1214\n",
      "Epoch 86/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1370 - val_loss: 0.1211\n",
      "Epoch 87/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1367 - val_loss: 0.1208\n",
      "Epoch 88/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1365 - val_loss: 0.1212\n",
      "Epoch 89/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1363 - val_loss: 0.1208\n",
      "Epoch 90/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1360 - val_loss: 0.1203\n",
      "Epoch 91/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1358 - val_loss: 0.1201\n",
      "Epoch 92/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1355 - val_loss: 0.1197\n",
      "Epoch 93/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1353 - val_loss: 0.1203\n",
      "Epoch 94/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1350 - val_loss: 0.1194\n",
      "Epoch 95/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1348 - val_loss: 0.1200\n",
      "Epoch 96/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1346 - val_loss: 0.1199\n",
      "Epoch 97/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1343 - val_loss: 0.1193\n",
      "Epoch 98/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1341 - val_loss: 0.1196\n",
      "Epoch 99/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1339 - val_loss: 0.1191\n",
      "Epoch 100/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1336 - val_loss: 0.1190\n",
      "Epoch 101/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1334 - val_loss: 0.1188\n",
      "Epoch 102/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1332 - val_loss: 0.1188\n",
      "Epoch 103/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1330 - val_loss: 0.1185\n",
      "Epoch 104/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1328 - val_loss: 0.1185\n",
      "Epoch 105/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1326 - val_loss: 0.1180\n",
      "Epoch 106/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1324 - val_loss: 0.1183\n",
      "Epoch 107/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1322 - val_loss: 0.1175\n",
      "Epoch 108/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1320 - val_loss: 0.1178\n",
      "Epoch 109/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1318 - val_loss: 0.1173\n",
      "Epoch 110/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1316 - val_loss: 0.1179\n",
      "Epoch 111/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1315 - val_loss: 0.1176\n",
      "Epoch 112/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1313 - val_loss: 0.1174\n",
      "Epoch 113/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1312 - val_loss: 0.1166\n",
      "Epoch 114/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1310 - val_loss: 0.1171\n",
      "Epoch 115/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1308 - val_loss: 0.1169\n",
      "Epoch 116/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1307 - val_loss: 0.1171\n",
      "Epoch 117/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1306 - val_loss: 0.1163\n",
      "Epoch 118/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1304 - val_loss: 0.1167\n",
      "Epoch 119/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1303 - val_loss: 0.1165\n",
      "Epoch 120/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1301 - val_loss: 0.1165\n",
      "Epoch 121/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1300 - val_loss: 0.1161\n",
      "Epoch 122/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1299 - val_loss: 0.1164\n",
      "Epoch 123/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1297 - val_loss: 0.1161\n",
      "Epoch 124/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1296 - val_loss: 0.1161\n",
      "Epoch 125/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1294 - val_loss: 0.1161\n",
      "Epoch 126/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1293 - val_loss: 0.1161\n",
      "Epoch 127/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1292 - val_loss: 0.1157\n",
      "Epoch 128/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1290 - val_loss: 0.1160\n",
      "Epoch 129/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1289 - val_loss: 0.1154\n",
      "Epoch 130/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1288 - val_loss: 0.1160\n",
      "Epoch 131/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1286 - val_loss: 0.1155\n",
      "Epoch 132/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1285 - val_loss: 0.1152\n",
      "Epoch 133/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1283 - val_loss: 0.1159\n",
      "Epoch 134/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1282 - val_loss: 0.1155\n",
      "Epoch 135/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1281 - val_loss: 0.1152\n",
      "Epoch 136/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1279 - val_loss: 0.1153\n",
      "Epoch 137/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1278 - val_loss: 0.1149\n",
      "Epoch 138/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1276 - val_loss: 0.1147\n",
      "Epoch 139/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1275 - val_loss: 0.1151\n",
      "Epoch 140/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1274 - val_loss: 0.1149\n",
      "Epoch 141/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1272 - val_loss: 0.1149\n",
      "Epoch 142/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1271 - val_loss: 0.1149\n",
      "Epoch 143/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1269 - val_loss: 0.1147\n",
      "Epoch 144/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1268 - val_loss: 0.1144\n",
      "Epoch 145/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1267 - val_loss: 0.1140\n",
      "Epoch 146/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1266 - val_loss: 0.1141\n",
      "Epoch 147/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1264 - val_loss: 0.1146\n",
      "Epoch 148/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1263 - val_loss: 0.1142\n",
      "Epoch 149/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1262 - val_loss: 0.1143\n",
      "Epoch 150/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1261 - val_loss: 0.1139\n",
      "Epoch 151/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1259 - val_loss: 0.1136\n",
      "Epoch 152/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1258 - val_loss: 0.1138\n",
      "Epoch 153/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1257 - val_loss: 0.1136\n",
      "Epoch 154/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1256 - val_loss: 0.1138\n",
      "Epoch 155/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1255 - val_loss: 0.1138\n",
      "Epoch 156/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1254 - val_loss: 0.1134\n",
      "Epoch 157/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1253 - val_loss: 0.1134\n",
      "Epoch 158/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1252 - val_loss: 0.1138\n",
      "Epoch 159/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1251 - val_loss: 0.1137\n",
      "Epoch 160/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1250 - val_loss: 0.1130\n",
      "Epoch 161/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1249 - val_loss: 0.1135\n",
      "Epoch 162/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1248 - val_loss: 0.1129\n",
      "Epoch 163/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1248 - val_loss: 0.1132\n",
      "Epoch 164/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1247 - val_loss: 0.1134\n",
      "Epoch 165/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1246 - val_loss: 0.1131\n",
      "Epoch 166/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1245 - val_loss: 0.1134\n",
      "Epoch 167/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1244 - val_loss: 0.1131\n",
      "Epoch 168/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1244 - val_loss: 0.1134\n",
      "Epoch 169/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1243 - val_loss: 0.1134\n",
      "Epoch 170/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1242 - val_loss: 0.1137\n",
      "Epoch 171/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1241 - val_loss: 0.1135\n",
      "Epoch 172/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1241 - val_loss: 0.1132\n",
      "Epoch 173/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1240 - val_loss: 0.1129\n",
      "Epoch 174/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1240 - val_loss: 0.1130\n",
      "Epoch 175/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1239 - val_loss: 0.1133\n",
      "Epoch 176/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1238 - val_loss: 0.1131\n",
      "Epoch 177/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1238 - val_loss: 0.1130\n",
      "Epoch 178/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1237 - val_loss: 0.1130\n",
      "Epoch 179/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1237 - val_loss: 0.1128\n",
      "Epoch 180/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1236 - val_loss: 0.1129\n",
      "Epoch 181/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1236 - val_loss: 0.1130\n",
      "Epoch 182/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1235 - val_loss: 0.1131\n",
      "Epoch 183/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1234 - val_loss: 0.1134\n",
      "Epoch 184/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1234 - val_loss: 0.1130\n",
      "Epoch 185/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1233 - val_loss: 0.1135\n",
      "Epoch 186/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1233 - val_loss: 0.1133\n",
      "Epoch 187/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1233 - val_loss: 0.1132\n",
      "Epoch 188/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1232 - val_loss: 0.1138\n",
      "Epoch 189/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1232 - val_loss: 0.1127\n",
      "Epoch 190/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1231 - val_loss: 0.1129\n",
      "Epoch 191/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1231 - val_loss: 0.1134\n",
      "Epoch 192/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1230 - val_loss: 0.1131\n",
      "Epoch 193/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1230 - val_loss: 0.1129\n",
      "Epoch 194/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1229 - val_loss: 0.1128\n",
      "Epoch 195/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1229 - val_loss: 0.1130\n",
      "Epoch 196/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1229 - val_loss: 0.1129\n",
      "Epoch 197/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1228 - val_loss: 0.1129\n",
      "Epoch 198/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1228 - val_loss: 0.1129\n",
      "Epoch 199/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1227 - val_loss: 0.1130\n",
      "Epoch 200/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1227 - val_loss: 0.1134\n",
      "Epoch 201/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1227 - val_loss: 0.1127\n",
      "Epoch 202/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1226 - val_loss: 0.1130\n",
      "Epoch 203/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1226 - val_loss: 0.1126\n",
      "Epoch 204/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1225 - val_loss: 0.1128\n",
      "Epoch 205/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1225 - val_loss: 0.1129\n",
      "Epoch 206/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1225 - val_loss: 0.1127\n",
      "Epoch 207/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1224 - val_loss: 0.1127\n",
      "Epoch 208/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1224 - val_loss: 0.1133\n",
      "Epoch 209/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1224 - val_loss: 0.1132\n",
      "Epoch 210/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1223 - val_loss: 0.1128\n",
      "Epoch 211/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1223 - val_loss: 0.1131\n",
      "Epoch 212/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1223 - val_loss: 0.1131\n",
      "Epoch 213/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1222 - val_loss: 0.1137\n",
      "Epoch 214/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1222 - val_loss: 0.1129\n",
      "Epoch 215/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1222 - val_loss: 0.1131\n",
      "Epoch 216/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1221 - val_loss: 0.1137\n",
      "Epoch 217/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1221 - val_loss: 0.1134\n",
      "Epoch 218/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1221 - val_loss: 0.1135\n",
      "Epoch 219/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1220 - val_loss: 0.1131\n",
      "Epoch 220/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1220 - val_loss: 0.1136\n",
      "Epoch 221/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1220 - val_loss: 0.1133\n",
      "Epoch 222/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1219 - val_loss: 0.1133\n",
      "Epoch 223/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1219 - val_loss: 0.1127\n",
      "Epoch 224/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1219 - val_loss: 0.1130\n",
      "Epoch 225/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1219 - val_loss: 0.1128\n",
      "Epoch 226/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1218 - val_loss: 0.1132\n",
      "Epoch 227/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1218 - val_loss: 0.1134\n",
      "Epoch 228/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1218 - val_loss: 0.1132\n",
      "Epoch 229/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1217 - val_loss: 0.1132\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1217 - val_loss: 0.1132\n",
      "Epoch 231/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1217 - val_loss: 0.1134\n",
      "Epoch 232/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1217 - val_loss: 0.1136\n",
      "Epoch 233/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1216 - val_loss: 0.1134\n",
      "Epoch 234/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1216 - val_loss: 0.1128\n",
      "Epoch 235/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1216 - val_loss: 0.1132\n",
      "Epoch 236/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1216 - val_loss: 0.1130\n",
      "Epoch 237/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1215 - val_loss: 0.1132\n",
      "Epoch 238/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1215 - val_loss: 0.1128\n",
      "Epoch 239/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1215 - val_loss: 0.1131\n",
      "Epoch 240/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1215 - val_loss: 0.1133\n",
      "Epoch 241/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1214 - val_loss: 0.1139\n",
      "Epoch 242/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1214 - val_loss: 0.1137\n",
      "Epoch 243/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1214 - val_loss: 0.1132\n",
      "Epoch 244/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1214 - val_loss: 0.1138\n",
      "Epoch 245/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1213 - val_loss: 0.1136\n",
      "Epoch 246/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1213 - val_loss: 0.1137\n",
      "Epoch 247/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1213 - val_loss: 0.1136\n",
      "Epoch 248/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1213 - val_loss: 0.1137\n",
      "Epoch 249/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1212 - val_loss: 0.1133\n",
      "Epoch 250/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1212 - val_loss: 0.1136\n",
      "Epoch 251/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1212 - val_loss: 0.1138\n",
      "Epoch 252/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1212 - val_loss: 0.1140\n",
      "Epoch 253/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1212 - val_loss: 0.1132\n",
      "Epoch 254/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1211 - val_loss: 0.1140\n",
      "Epoch 255/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1211 - val_loss: 0.1132\n",
      "Epoch 256/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1211 - val_loss: 0.1138\n",
      "Epoch 257/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1211 - val_loss: 0.1136\n",
      "Epoch 258/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1210 - val_loss: 0.1137\n",
      "Epoch 259/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1210 - val_loss: 0.1139\n",
      "Epoch 260/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1210 - val_loss: 0.1141\n",
      "Epoch 261/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1210 - val_loss: 0.1137\n",
      "Epoch 262/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1210 - val_loss: 0.1138\n",
      "Epoch 263/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1209 - val_loss: 0.1138\n",
      "Epoch 264/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1209 - val_loss: 0.1137\n",
      "Epoch 265/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1209 - val_loss: 0.1138\n",
      "Epoch 266/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1209 - val_loss: 0.1135\n",
      "Epoch 267/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1209 - val_loss: 0.1134\n",
      "Epoch 268/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1208 - val_loss: 0.1145\n",
      "Epoch 269/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1208 - val_loss: 0.1142\n",
      "Epoch 270/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1208 - val_loss: 0.1141\n",
      "Epoch 271/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1208 - val_loss: 0.1143\n",
      "Epoch 272/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1208 - val_loss: 0.1140\n",
      "Epoch 273/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1207 - val_loss: 0.1140\n",
      "Epoch 274/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1207 - val_loss: 0.1136\n",
      "Epoch 275/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1207 - val_loss: 0.1142\n",
      "Epoch 276/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1207 - val_loss: 0.1140\n",
      "Epoch 277/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1207 - val_loss: 0.1143\n",
      "Epoch 278/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1207 - val_loss: 0.1142\n",
      "Epoch 279/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1206 - val_loss: 0.1139\n",
      "Epoch 280/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1206 - val_loss: 0.1143\n",
      "Epoch 281/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1206 - val_loss: 0.1141\n",
      "Epoch 282/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1206 - val_loss: 0.1138\n",
      "Epoch 283/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1206 - val_loss: 0.1144\n",
      "Epoch 284/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1205 - val_loss: 0.1143\n",
      "Epoch 285/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1205 - val_loss: 0.1147\n",
      "Epoch 286/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1205 - val_loss: 0.1143\n",
      "Epoch 287/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1205 - val_loss: 0.1141\n",
      "Epoch 288/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1205 - val_loss: 0.1143\n",
      "Epoch 289/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1205 - val_loss: 0.1145\n",
      "Epoch 290/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1204 - val_loss: 0.1151\n",
      "Epoch 291/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1204 - val_loss: 0.1142\n",
      "Epoch 292/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1204 - val_loss: 0.1146\n",
      "Epoch 293/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1204 - val_loss: 0.1144\n",
      "Epoch 294/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1204 - val_loss: 0.1149\n",
      "Epoch 295/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1204 - val_loss: 0.1145\n",
      "Epoch 296/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1203 - val_loss: 0.1146\n",
      "Epoch 297/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1203 - val_loss: 0.1147\n",
      "Epoch 298/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1203 - val_loss: 0.1150\n",
      "Epoch 299/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1203 - val_loss: 0.1151\n",
      "Epoch 300/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1203 - val_loss: 0.1143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2aac049dd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=300,\n",
    "                batch_size=512,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAKID/D9tojZyi1VT2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2aa00f5f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "    # Arguments\n",
    "        y: true labels, numpy.array with shape `(n_samples,)`\n",
    "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
    "    # Return\n",
    "        accuracy, in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    print(D)\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    print(w)\n",
    "    from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "    ind = linear_assignment(w.max() - w)\n",
    "    print([w[i, j] for i, j in ind])\n",
    "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[ 937 1115  723]\n",
      " [ 918 1130 1855]\n",
      " [1535 1048  739]]\n",
      "0.4505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "result = np.zeros((len(y_test), 2))\n",
    "for index, item in enumerate(y_test):\n",
    "    result[index] = (y_test[index], np.max(encoded_imgs[index]))\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, n_init=20)\n",
    "y_pred = kmeans.fit_predict((encoded_imgs))\n",
    "print(acc(y_test, y_pred))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3379 - val_loss: 0.2893\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2891 - val_loss: 0.2641\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2724 - val_loss: 0.2472\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2666 - val_loss: 0.2430\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2633 - val_loss: 0.2344\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2581 - val_loss: 0.2200\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2513 - val_loss: 0.2053\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2441 - val_loss: 0.2049\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2359 - val_loss: 0.2001\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2295 - val_loss: 0.1962\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2241 - val_loss: 0.1874\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2195 - val_loss: 0.1922\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2153 - val_loss: 0.1906\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2098 - val_loss: 0.1894\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2037 - val_loss: 0.1833\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1974 - val_loss: 0.1825\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1923 - val_loss: 0.1812\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1868 - val_loss: 0.1763\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1819 - val_loss: 0.1750\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1767 - val_loss: 0.1727\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1711 - val_loss: 0.1710\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1662 - val_loss: 0.1849\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1616 - val_loss: 0.1717\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1569 - val_loss: 0.1815\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1527 - val_loss: 0.1697\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1486 - val_loss: 0.1755\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1454 - val_loss: 0.1802\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1417 - val_loss: 0.1761\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1386 - val_loss: 0.1671\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1354 - val_loss: 0.1815\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1323 - val_loss: 0.1677\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1291 - val_loss: 0.1726\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1266 - val_loss: 0.1790\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1241 - val_loss: 0.1703\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1216 - val_loss: 0.1777\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1197 - val_loss: 0.1771\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1181 - val_loss: 0.1671\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1162 - val_loss: 0.1831\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1147 - val_loss: 0.1688\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1130 - val_loss: 0.1710\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1119 - val_loss: 0.1639\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1106 - val_loss: 0.1639\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1096 - val_loss: 0.1591\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1084 - val_loss: 0.1518\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1073 - val_loss: 0.1549\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1066 - val_loss: 0.1697\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1057 - val_loss: 0.1528\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1048 - val_loss: 0.1598\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1043 - val_loss: 0.1525\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1031 - val_loss: 0.1661\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1027 - val_loss: 0.1649\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1021 - val_loss: 0.1556\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1013 - val_loss: 0.1583\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1006 - val_loss: 0.1576\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1002 - val_loss: 0.1507\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0996 - val_loss: 0.1522\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0993 - val_loss: 0.1507\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0986 - val_loss: 0.1632\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0981 - val_loss: 0.1518\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0977 - val_loss: 0.1496\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0973 - val_loss: 0.1459\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0968 - val_loss: 0.1512\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0964 - val_loss: 0.1560\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0960 - val_loss: 0.1470\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0957 - val_loss: 0.1551\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0953 - val_loss: 0.1553\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0950 - val_loss: 0.1540\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0945 - val_loss: 0.1510\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0941 - val_loss: 0.1526\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0939 - val_loss: 0.1483\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0937 - val_loss: 0.1515\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0932 - val_loss: 0.1581\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0932 - val_loss: 0.1448\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0930 - val_loss: 0.1395\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0924 - val_loss: 0.1460\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0922 - val_loss: 0.1456\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0918 - val_loss: 0.1561\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0917 - val_loss: 0.1446\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0916 - val_loss: 0.1492\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0911 - val_loss: 0.1512\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0911 - val_loss: 0.1421\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0909 - val_loss: 0.1459\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0905 - val_loss: 0.1485\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0904 - val_loss: 0.1478\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0902 - val_loss: 0.1543\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0900 - val_loss: 0.1499\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0897 - val_loss: 0.1470\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0897 - val_loss: 0.1425\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0895 - val_loss: 0.1370\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0891 - val_loss: 0.1478\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0889 - val_loss: 0.1474\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0890 - val_loss: 0.1474\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0887 - val_loss: 0.1482\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0888 - val_loss: 0.1410\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0884 - val_loss: 0.1448\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0884 - val_loss: 0.1402\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0881 - val_loss: 0.1409\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0879 - val_loss: 0.1492\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0879 - val_loss: 0.1452\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0878 - val_loss: 0.1471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2aa00f74d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(512, activation='relu')(input_img)\n",
    "encoded = Dense(256, activation='relu')(encoded)\n",
    "encoded = Dense(128, activation='relu')(encoded)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(256, activation='relu')(decoded)\n",
    "decoded = Dense(512, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMgAD3EAAAAAAAAy8P8A/mYjyeXZ7ogAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a3c651f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = autoencoder.predict(x_test)\n",
    "decoded_imgs = autoencoder.predict(encoded_imgs)\n",
    "\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[1339  994  704]\n",
      " [ 570 1050 1778]\n",
      " [1481 1249  835]]\n",
      "[1339, 1778, 1249]\n",
      "0.4366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3, n_init=20)\n",
    "y_pred = kmeans.fit_predict((encoded_imgs))\n",
    "print(acc(y_test, y_pred))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3114 - val_loss: 0.2041\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.2117 - val_loss: 0.1568\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1788 - val_loss: 0.1415\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1597 - val_loss: 0.1397\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1468 - val_loss: 0.1231\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1373 - val_loss: 0.1210\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1304 - val_loss: 0.1151\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1253 - val_loss: 0.1131\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1216 - val_loss: 0.1070\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1187 - val_loss: 0.1047\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1160 - val_loss: 0.1042\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1143 - val_loss: 0.1031\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1128 - val_loss: 0.1029\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1116 - val_loss: 0.1006\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1106 - val_loss: 0.1013\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1097 - val_loss: 0.0995\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1086 - val_loss: 0.0986\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1076 - val_loss: 0.1024\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1072 - val_loss: 0.1016\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1066 - val_loss: 0.0977\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1062 - val_loss: 0.0975\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1054 - val_loss: 0.0992\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1047 - val_loss: 0.0992\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1044 - val_loss: 0.0986\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1037 - val_loss: 0.0973\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1034 - val_loss: 0.0954\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1029 - val_loss: 0.0950\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1024 - val_loss: 0.0996\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1021 - val_loss: 0.0943\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1019 - val_loss: 0.0957\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1013 - val_loss: 0.0983\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1010 - val_loss: 0.0941\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1009 - val_loss: 0.0932\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1006 - val_loss: 0.0932\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1003 - val_loss: 0.0962\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1002 - val_loss: 0.0962\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1001 - val_loss: 0.0923\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0995 - val_loss: 0.0936\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0994 - val_loss: 0.0921\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0993 - val_loss: 0.0914\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0990 - val_loss: 0.0956\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0990 - val_loss: 0.0913\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0988 - val_loss: 0.0955\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0987 - val_loss: 0.0905\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0986 - val_loss: 0.0908\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0982 - val_loss: 0.0931\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0981 - val_loss: 0.0923\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0980 - val_loss: 0.0909\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0980 - val_loss: 0.0895\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0978 - val_loss: 0.0926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2aa00f5850>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngAzgIQ4AAAAAAEAG8BAHAAAAAAAgA/4fjCqVoTuHVukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a0262ed10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = autoencoder.predict(x_test)\n",
    "decoded_imgs = autoencoder.predict(encoded_imgs)\n",
    "\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[1933 1347 1115]\n",
      " [   0  721 1470]\n",
      " [1457 1225  732]]\n",
      "[1933, 1470, 1225]\n",
      "0.4628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs = np.reshape(encoded_imgs, (len(x_test), 28*28*1))  # adapt this if using `channels_first` image data format\n",
    "kmeans = KMeans(n_clusters=3, n_init=20)\n",
    "y_pred = kmeans.fit_predict((encoded_imgs))\n",
    "print(acc(y_test, y_pred))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), 28*28*1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28*28*1))  # adapt this if using `channels_first` image data format\n",
    "est = KMeans(n_clusters=3, n_jobs=20)\n",
    "y_pred = est.fit(x_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[ 278  915  677]\n",
      " [ 457  557 1424]\n",
      " [2655 1821 1216]]\n",
      "[915, 1424, 2655]\n",
      "0.4994\n"
     ]
    }
   ],
   "source": [
    "print(acc(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
