{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, struct\n",
    "import matplotlib as plt\n",
    "from array import array as pyarray\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from pylab import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NMNIST(dataset=\"training\", digits=range(10), path=r'E:\\Users\\Shashi\\OneDrive\\Datasets\\Shapes'):\n",
    "    \n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'Shapes_1_1_Train_Features.dat')\n",
    "        fname_lbl = os.path.join(path, 'Shapes_1_1_Train_Labels.dat')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 'Shapes_1_1_Test_Features.dat')\n",
    "        fname_lbl = os.path.join(path, 'Shapes_1_1_Test_Labels.dat')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    lbl = np.fromfile(flbl, dtype=np.uint8)\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    img = np.fromfile(fimg, dtype=np.uint8)\n",
    "    fimg.close()\n",
    "\n",
    "    size=len(lbl)\n",
    "\n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    rows=28;cols=28;\n",
    "\n",
    "    images = zeros((N, rows, cols), dtype=uint8)\n",
    "    labels = zeros((N, 1), dtype=int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectortoimg(v,show=True):\n",
    "    plt.imshow(v.reshape(28, 28),interpolation='None', cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niR9C/Q2H4kPRU0/tVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3e938af50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path= os.path.join(os.path.curdir, 'data')\n",
    "images, labels = load_NMNIST('training', digits=[0,1,2], path=path)\n",
    "\n",
    "flatimages = list()\n",
    "for i in images:\n",
    "    flatimages.append(i.ravel())\n",
    "x_train = asarray(flatimages) # X now contains 60000 feature vectors, each of dimension 784\n",
    "y_train=labels # T contains class labels with 0->Triangle, 1->Square, 2->Pizza\n",
    "vectortoimg(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Checking multiple training vectors by plotting images.\\nBe patient:\")\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "nrows=15\n",
    "ncols=15\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        plt.subplot(nrows, ncols, row*ncols+col + 1)\n",
    "        vectortoimg(x_train[np.random.randint(len(y_train))],show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_NMNIST('testing', digits=[0,1,2], path=path)\n",
    "flatimages = list()\n",
    "for i in images:\n",
    "    flatimages.append(i.ravel())\n",
    "x_test = asarray(flatimages) # X now contains 60000 feature vectors, each of dimension 784\n",
    "y_test = labels # T contains class labels with 0->Triangle, 1->Square, 2->Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single fully-connected neural layer as encoder and as decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 3 floats -> 3 floats represents 3 classes\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's also create a separate encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Crossentropy loss, and Adadelta Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3984 - val_loss: 0.2993\n",
      "Epoch 2/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3118 - val_loss: 0.2869\n",
      "Epoch 3/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2946 - val_loss: 0.2637\n",
      "Epoch 4/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2776 - val_loss: 0.2441\n",
      "Epoch 5/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2679 - val_loss: 0.2299\n",
      "Epoch 6/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2622 - val_loss: 0.2217\n",
      "Epoch 7/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2584 - val_loss: 0.2165\n",
      "Epoch 8/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2548 - val_loss: 0.2128\n",
      "Epoch 9/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2507 - val_loss: 0.2096\n",
      "Epoch 10/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2460 - val_loss: 0.2052\n",
      "Epoch 11/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2408 - val_loss: 0.2008\n",
      "Epoch 12/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2353 - val_loss: 0.1966\n",
      "Epoch 13/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2297 - val_loss: 0.1931\n",
      "Epoch 14/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2242 - val_loss: 0.1879\n",
      "Epoch 15/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2189 - val_loss: 0.1840\n",
      "Epoch 16/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2138 - val_loss: 0.1790\n",
      "Epoch 17/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2090 - val_loss: 0.1754\n",
      "Epoch 18/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2044 - val_loss: 0.1719\n",
      "Epoch 19/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2001 - val_loss: 0.1682\n",
      "Epoch 20/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1960 - val_loss: 0.1644\n",
      "Epoch 21/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1921 - val_loss: 0.1610\n",
      "Epoch 22/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1885 - val_loss: 0.1581\n",
      "Epoch 23/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1850 - val_loss: 0.1558\n",
      "Epoch 24/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1817 - val_loss: 0.1528\n",
      "Epoch 25/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1786 - val_loss: 0.1503\n",
      "Epoch 26/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1756 - val_loss: 0.1479\n",
      "Epoch 27/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1728 - val_loss: 0.1457\n",
      "Epoch 28/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1702 - val_loss: 0.1438\n",
      "Epoch 29/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1677 - val_loss: 0.1420\n",
      "Epoch 30/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1654 - val_loss: 0.1403\n",
      "Epoch 31/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1632 - val_loss: 0.1387\n",
      "Epoch 32/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1611 - val_loss: 0.1372\n",
      "Epoch 33/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1592 - val_loss: 0.1354\n",
      "Epoch 34/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1574 - val_loss: 0.1344\n",
      "Epoch 35/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1557 - val_loss: 0.1331\n",
      "Epoch 36/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1540 - val_loss: 0.1320\n",
      "Epoch 37/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1525 - val_loss: 0.1305\n",
      "Epoch 38/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1510 - val_loss: 0.1292\n",
      "Epoch 39/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1496 - val_loss: 0.1281\n",
      "Epoch 40/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1482 - val_loss: 0.1272\n",
      "Epoch 41/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1469 - val_loss: 0.1258\n",
      "Epoch 42/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1457 - val_loss: 0.1250\n",
      "Epoch 43/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1446 - val_loss: 0.1242\n",
      "Epoch 44/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1435 - val_loss: 0.1234\n",
      "Epoch 45/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1424 - val_loss: 0.1225\n",
      "Epoch 46/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1415 - val_loss: 0.1215\n",
      "Epoch 47/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1405 - val_loss: 0.1207\n",
      "Epoch 48/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1396 - val_loss: 0.1204\n",
      "Epoch 49/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1388 - val_loss: 0.1194\n",
      "Epoch 50/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1380 - val_loss: 0.1188\n",
      "Epoch 51/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1373 - val_loss: 0.1179\n",
      "Epoch 52/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1365 - val_loss: 0.1174\n",
      "Epoch 53/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1358 - val_loss: 0.1166\n",
      "Epoch 54/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1352 - val_loss: 0.1162\n",
      "Epoch 55/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1346 - val_loss: 0.1160\n",
      "Epoch 56/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1340 - val_loss: 0.1151\n",
      "Epoch 57/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1334 - val_loss: 0.1145\n",
      "Epoch 58/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1328 - val_loss: 0.1148\n",
      "Epoch 59/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1323 - val_loss: 0.1141\n",
      "Epoch 60/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1318 - val_loss: 0.1135\n",
      "Epoch 61/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1313 - val_loss: 0.1134\n",
      "Epoch 62/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1308 - val_loss: 0.1130\n",
      "Epoch 63/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1303 - val_loss: 0.1127\n",
      "Epoch 64/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1299 - val_loss: 0.1120\n",
      "Epoch 65/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1294 - val_loss: 0.1123\n",
      "Epoch 66/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1290 - val_loss: 0.1118\n",
      "Epoch 67/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1286 - val_loss: 0.1113\n",
      "Epoch 68/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1283 - val_loss: 0.1115\n",
      "Epoch 69/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1279 - val_loss: 0.1110\n",
      "Epoch 70/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1275 - val_loss: 0.1110\n",
      "Epoch 71/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1272 - val_loss: 0.1107\n",
      "Epoch 72/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1269 - val_loss: 0.1106\n",
      "Epoch 73/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1266 - val_loss: 0.1105\n",
      "Epoch 74/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1263 - val_loss: 0.1104\n",
      "Epoch 75/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1260 - val_loss: 0.1102\n",
      "Epoch 76/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1257 - val_loss: 0.1099\n",
      "Epoch 77/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1254 - val_loss: 0.1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1252 - val_loss: 0.1098\n",
      "Epoch 79/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1249 - val_loss: 0.1095\n",
      "Epoch 80/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1247 - val_loss: 0.1095\n",
      "Epoch 81/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1245 - val_loss: 0.1091\n",
      "Epoch 82/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1242 - val_loss: 0.1093\n",
      "Epoch 83/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1240 - val_loss: 0.1092\n",
      "Epoch 84/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1238 - val_loss: 0.1094\n",
      "Epoch 85/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1236 - val_loss: 0.1093\n",
      "Epoch 86/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1234 - val_loss: 0.1088\n",
      "Epoch 87/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1233 - val_loss: 0.1090\n",
      "Epoch 88/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1231 - val_loss: 0.1090\n",
      "Epoch 89/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1229 - val_loss: 0.1085\n",
      "Epoch 90/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1228 - val_loss: 0.1087\n",
      "Epoch 91/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1226 - val_loss: 0.1084\n",
      "Epoch 92/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1225 - val_loss: 0.1089\n",
      "Epoch 93/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1223 - val_loss: 0.1082\n",
      "Epoch 94/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1222 - val_loss: 0.1084\n",
      "Epoch 95/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1220 - val_loss: 0.1085\n",
      "Epoch 96/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1219 - val_loss: 0.1085\n",
      "Epoch 97/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1218 - val_loss: 0.1083\n",
      "Epoch 98/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1216 - val_loss: 0.1083\n",
      "Epoch 99/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1215 - val_loss: 0.1081\n",
      "Epoch 100/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1214 - val_loss: 0.1084\n",
      "Epoch 101/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1213 - val_loss: 0.1084\n",
      "Epoch 102/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1212 - val_loss: 0.1083\n",
      "Epoch 103/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1211 - val_loss: 0.1081\n",
      "Epoch 104/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1210 - val_loss: 0.1082\n",
      "Epoch 105/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1209 - val_loss: 0.1081\n",
      "Epoch 106/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1208 - val_loss: 0.1081\n",
      "Epoch 107/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1207 - val_loss: 0.1081\n",
      "Epoch 108/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1206 - val_loss: 0.1078\n",
      "Epoch 109/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1205 - val_loss: 0.1082\n",
      "Epoch 110/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1204 - val_loss: 0.1079\n",
      "Epoch 111/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1203 - val_loss: 0.1078\n",
      "Epoch 112/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1202 - val_loss: 0.1079\n",
      "Epoch 113/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1201 - val_loss: 0.1077\n",
      "Epoch 114/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1200 - val_loss: 0.1079\n",
      "Epoch 115/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1199 - val_loss: 0.1080\n",
      "Epoch 116/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1199 - val_loss: 0.1077\n",
      "Epoch 117/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1198 - val_loss: 0.1078\n",
      "Epoch 118/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1197 - val_loss: 0.1079\n",
      "Epoch 119/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1196 - val_loss: 0.1078\n",
      "Epoch 120/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1196 - val_loss: 0.1078\n",
      "Epoch 121/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1195 - val_loss: 0.1078\n",
      "Epoch 122/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1194 - val_loss: 0.1080\n",
      "Epoch 123/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1193 - val_loss: 0.1076\n",
      "Epoch 124/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1193 - val_loss: 0.1076\n",
      "Epoch 125/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1192 - val_loss: 0.1081\n",
      "Epoch 126/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1191 - val_loss: 0.1077\n",
      "Epoch 127/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1191 - val_loss: 0.1074\n",
      "Epoch 128/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1190 - val_loss: 0.1078\n",
      "Epoch 129/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1189 - val_loss: 0.1080\n",
      "Epoch 130/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1189 - val_loss: 0.1080\n",
      "Epoch 131/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1188 - val_loss: 0.1078\n",
      "Epoch 132/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1188 - val_loss: 0.1077\n",
      "Epoch 133/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1187 - val_loss: 0.1077\n",
      "Epoch 134/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1186 - val_loss: 0.1079\n",
      "Epoch 135/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1186 - val_loss: 0.1078\n",
      "Epoch 136/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1185 - val_loss: 0.1078\n",
      "Epoch 137/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1185 - val_loss: 0.1080\n",
      "Epoch 138/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1184 - val_loss: 0.1076\n",
      "Epoch 139/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1183 - val_loss: 0.1078\n",
      "Epoch 140/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1183 - val_loss: 0.1079\n",
      "Epoch 141/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1182 - val_loss: 0.1080\n",
      "Epoch 142/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1182 - val_loss: 0.1079\n",
      "Epoch 143/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1181 - val_loss: 0.1079\n",
      "Epoch 144/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1181 - val_loss: 0.1077\n",
      "Epoch 145/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1180 - val_loss: 0.1077\n",
      "Epoch 146/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1180 - val_loss: 0.1078\n",
      "Epoch 147/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1179 - val_loss: 0.1078\n",
      "Epoch 148/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1179 - val_loss: 0.1077\n",
      "Epoch 149/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1178 - val_loss: 0.1077\n",
      "Epoch 150/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1178 - val_loss: 0.1081\n",
      "Epoch 151/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1177 - val_loss: 0.1077\n",
      "Epoch 152/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1177 - val_loss: 0.1075\n",
      "Epoch 153/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1176 - val_loss: 0.1079\n",
      "Epoch 154/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1176 - val_loss: 0.1073\n",
      "Epoch 155/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1176 - val_loss: 0.1078\n",
      "Epoch 156/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1175 - val_loss: 0.1078\n",
      "Epoch 157/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1175 - val_loss: 0.1075\n",
      "Epoch 158/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1174 - val_loss: 0.1079\n",
      "Epoch 159/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1174 - val_loss: 0.1078\n",
      "Epoch 160/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1173 - val_loss: 0.1078\n",
      "Epoch 161/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1173 - val_loss: 0.1077\n",
      "Epoch 162/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1173 - val_loss: 0.1079\n",
      "Epoch 163/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1172 - val_loss: 0.1079\n",
      "Epoch 164/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1172 - val_loss: 0.1076\n",
      "Epoch 165/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1171 - val_loss: 0.1075\n",
      "Epoch 166/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1171 - val_loss: 0.1078\n",
      "Epoch 167/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1171 - val_loss: 0.1078\n",
      "Epoch 168/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1170 - val_loss: 0.1081\n",
      "Epoch 169/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1170 - val_loss: 0.1074\n",
      "Epoch 170/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1169 - val_loss: 0.1080\n",
      "Epoch 171/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1169 - val_loss: 0.1079\n",
      "Epoch 172/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1169 - val_loss: 0.1077\n",
      "Epoch 173/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1168 - val_loss: 0.1079\n",
      "Epoch 174/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1168 - val_loss: 0.1079\n",
      "Epoch 175/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1168 - val_loss: 0.1080\n",
      "Epoch 176/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1167 - val_loss: 0.1079\n",
      "Epoch 177/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1167 - val_loss: 0.1077\n",
      "Epoch 178/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1167 - val_loss: 0.1078\n",
      "Epoch 179/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1166 - val_loss: 0.1085\n",
      "Epoch 180/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1166 - val_loss: 0.1078\n",
      "Epoch 181/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1166 - val_loss: 0.1084\n",
      "Epoch 182/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1165 - val_loss: 0.1075\n",
      "Epoch 183/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1165 - val_loss: 0.1081\n",
      "Epoch 184/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1165 - val_loss: 0.1080\n",
      "Epoch 185/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1164 - val_loss: 0.1080\n",
      "Epoch 186/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1164 - val_loss: 0.1082\n",
      "Epoch 187/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1164 - val_loss: 0.1083\n",
      "Epoch 188/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1163 - val_loss: 0.1084\n",
      "Epoch 189/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1163 - val_loss: 0.1084\n",
      "Epoch 190/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1163 - val_loss: 0.1080\n",
      "Epoch 191/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1162 - val_loss: 0.1081\n",
      "Epoch 192/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1162 - val_loss: 0.1081\n",
      "Epoch 193/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1162 - val_loss: 0.1081\n",
      "Epoch 194/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1162 - val_loss: 0.1080\n",
      "Epoch 195/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1161 - val_loss: 0.1080\n",
      "Epoch 196/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1161 - val_loss: 0.1081\n",
      "Epoch 197/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1161 - val_loss: 0.1081\n",
      "Epoch 198/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1160 - val_loss: 0.1081\n",
      "Epoch 199/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1160 - val_loss: 0.1083\n",
      "Epoch 200/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1160 - val_loss: 0.1081\n",
      "Epoch 201/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1159 - val_loss: 0.1079\n",
      "Epoch 202/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1159 - val_loss: 0.1082\n",
      "Epoch 203/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1159 - val_loss: 0.1081\n",
      "Epoch 204/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1159 - val_loss: 0.1086\n",
      "Epoch 205/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1158 - val_loss: 0.1084\n",
      "Epoch 206/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1158 - val_loss: 0.1082\n",
      "Epoch 207/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1158 - val_loss: 0.1085\n",
      "Epoch 208/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1158 - val_loss: 0.1084\n",
      "Epoch 209/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1157 - val_loss: 0.1080\n",
      "Epoch 210/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1157 - val_loss: 0.1083\n",
      "Epoch 211/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1157 - val_loss: 0.1083\n",
      "Epoch 212/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1157 - val_loss: 0.1086\n",
      "Epoch 213/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1156 - val_loss: 0.1085\n",
      "Epoch 214/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1156 - val_loss: 0.1086\n",
      "Epoch 215/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1156 - val_loss: 0.1081\n",
      "Epoch 216/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1156 - val_loss: 0.1083\n",
      "Epoch 217/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1155 - val_loss: 0.1085\n",
      "Epoch 218/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1155 - val_loss: 0.1082\n",
      "Epoch 219/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1155 - val_loss: 0.1087\n",
      "Epoch 220/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1155 - val_loss: 0.1085\n",
      "Epoch 221/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1154 - val_loss: 0.1088\n",
      "Epoch 222/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1154 - val_loss: 0.1086\n",
      "Epoch 223/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1154 - val_loss: 0.1084\n",
      "Epoch 224/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1154 - val_loss: 0.1088\n",
      "Epoch 225/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1153 - val_loss: 0.1089\n",
      "Epoch 226/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1153 - val_loss: 0.1088\n",
      "Epoch 227/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1153 - val_loss: 0.1087\n",
      "Epoch 228/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1153 - val_loss: 0.1086\n",
      "Epoch 229/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1153 - val_loss: 0.1087\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1152 - val_loss: 0.1087\n",
      "Epoch 231/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1152 - val_loss: 0.1088\n",
      "Epoch 232/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1152 - val_loss: 0.1088\n",
      "Epoch 233/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1152 - val_loss: 0.1087\n",
      "Epoch 234/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1151 - val_loss: 0.1088\n",
      "Epoch 235/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1151 - val_loss: 0.1087\n",
      "Epoch 236/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1151 - val_loss: 0.1088\n",
      "Epoch 237/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1151 - val_loss: 0.1089\n",
      "Epoch 238/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1151 - val_loss: 0.1085\n",
      "Epoch 239/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1150 - val_loss: 0.1089\n",
      "Epoch 240/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1150 - val_loss: 0.1089\n",
      "Epoch 241/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1150 - val_loss: 0.1089\n",
      "Epoch 242/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1150 - val_loss: 0.1088\n",
      "Epoch 243/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1150 - val_loss: 0.1089\n",
      "Epoch 244/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1149 - val_loss: 0.1088\n",
      "Epoch 245/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1149 - val_loss: 0.1090\n",
      "Epoch 246/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1149 - val_loss: 0.1090\n",
      "Epoch 247/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1149 - val_loss: 0.1088\n",
      "Epoch 248/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1149 - val_loss: 0.1091\n",
      "Epoch 249/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1148 - val_loss: 0.1089\n",
      "Epoch 250/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1148 - val_loss: 0.1089\n",
      "Epoch 251/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1148 - val_loss: 0.1088\n",
      "Epoch 252/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1148 - val_loss: 0.1091\n",
      "Epoch 253/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1148 - val_loss: 0.1092\n",
      "Epoch 254/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1147 - val_loss: 0.1095\n",
      "Epoch 255/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1147 - val_loss: 0.1092\n",
      "Epoch 256/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1147 - val_loss: 0.1090\n",
      "Epoch 257/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1147 - val_loss: 0.1090\n",
      "Epoch 258/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1147 - val_loss: 0.1094\n",
      "Epoch 259/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1147 - val_loss: 0.1094\n",
      "Epoch 260/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1146 - val_loss: 0.1089\n",
      "Epoch 261/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1146 - val_loss: 0.1094\n",
      "Epoch 262/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1146 - val_loss: 0.1093\n",
      "Epoch 263/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1146 - val_loss: 0.1094\n",
      "Epoch 264/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1146 - val_loss: 0.1091\n",
      "Epoch 265/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1145 - val_loss: 0.1095\n",
      "Epoch 266/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1145 - val_loss: 0.1098\n",
      "Epoch 267/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1145 - val_loss: 0.1096\n",
      "Epoch 268/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1145 - val_loss: 0.1098\n",
      "Epoch 269/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1145 - val_loss: 0.1097\n",
      "Epoch 270/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1145 - val_loss: 0.1094\n",
      "Epoch 271/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1144 - val_loss: 0.1096\n",
      "Epoch 272/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1144 - val_loss: 0.1096\n",
      "Epoch 273/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1144 - val_loss: 0.1095\n",
      "Epoch 274/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1144 - val_loss: 0.1097\n",
      "Epoch 275/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1144 - val_loss: 0.1092\n",
      "Epoch 276/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1144 - val_loss: 0.1096\n",
      "Epoch 277/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1143 - val_loss: 0.1101\n",
      "Epoch 278/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1143 - val_loss: 0.1098\n",
      "Epoch 279/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1143 - val_loss: 0.1098\n",
      "Epoch 280/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1143 - val_loss: 0.1099\n",
      "Epoch 281/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1143 - val_loss: 0.1095\n",
      "Epoch 282/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1143 - val_loss: 0.1099\n",
      "Epoch 283/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1142 - val_loss: 0.1098\n",
      "Epoch 284/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1142 - val_loss: 0.1098\n",
      "Epoch 285/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1142 - val_loss: 0.1099\n",
      "Epoch 286/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1142 - val_loss: 0.1104\n",
      "Epoch 287/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1142 - val_loss: 0.1103\n",
      "Epoch 288/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1142 - val_loss: 0.1095\n",
      "Epoch 289/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1141 - val_loss: 0.1099\n",
      "Epoch 290/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1141 - val_loss: 0.1099\n",
      "Epoch 291/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1141 - val_loss: 0.1102\n",
      "Epoch 292/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1141 - val_loss: 0.1106\n",
      "Epoch 293/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1141 - val_loss: 0.1101\n",
      "Epoch 294/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1141 - val_loss: 0.1099\n",
      "Epoch 295/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1140 - val_loss: 0.1103\n",
      "Epoch 296/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1140 - val_loss: 0.1103\n",
      "Epoch 297/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1140 - val_loss: 0.1104\n",
      "Epoch 298/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1140 - val_loss: 0.1104\n",
      "Epoch 299/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1140 - val_loss: 0.1104\n",
      "Epoch 300/300\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1140 - val_loss: 0.1106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc3e70b2890>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=300,\n",
    "                batch_size=512,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3e6c69b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "    # Arguments\n",
    "        y: true labels, numpy.array with shape `(n_samples,)`\n",
    "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
    "    # Return\n",
    "        accuracy, in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    print(D)\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    print(w)\n",
    "    from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "    ind = linear_assignment(w.max() - w)\n",
    "    print([w[i, j] for i, j in ind])\n",
    "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[1533 1058  744]\n",
      " [ 888 1086 1822]\n",
      " [ 969 1149  751]]\n",
      "[1533, 1822, 1149]\n",
      "0.4504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "result = np.zeros((len(y_test), 2))\n",
    "for index, item in enumerate(y_test):\n",
    "    result[index] = (y_test[index], np.max(encoded_imgs[index]))\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, n_init=20)\n",
    "y_pred = kmeans.fit_predict((encoded_imgs))\n",
    "print(acc(y_test, y_pred))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3479 - val_loss: 0.2875\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2944 - val_loss: 0.2784\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2780 - val_loss: 0.2548\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2690 - val_loss: 0.2527\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2653 - val_loss: 0.2482\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2627 - val_loss: 0.2386\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2609 - val_loss: 0.2349\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2594 - val_loss: 0.2273\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2567 - val_loss: 0.2173\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2517 - val_loss: 0.2120\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2479 - val_loss: 0.2113\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2449 - val_loss: 0.2096\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2422 - val_loss: 0.2095\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2394 - val_loss: 0.1999\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2353 - val_loss: 0.2026\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2285 - val_loss: 0.1979\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2213 - val_loss: 0.1971\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2154 - val_loss: 0.1908\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2096 - val_loss: 0.1923\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2040 - val_loss: 0.1888\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1990 - val_loss: 0.1865\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1943 - val_loss: 0.1847\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1898 - val_loss: 0.1932\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1860 - val_loss: 0.1753\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1822 - val_loss: 0.1736\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1789 - val_loss: 0.1724\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1756 - val_loss: 0.1716\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1723 - val_loss: 0.1667\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1693 - val_loss: 0.1644\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1666 - val_loss: 0.1641\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1637 - val_loss: 0.1691\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1608 - val_loss: 0.1734\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1575 - val_loss: 0.1761\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1540 - val_loss: 0.1650\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1508 - val_loss: 0.1648\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1470 - val_loss: 0.1696\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1443 - val_loss: 0.1626\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1411 - val_loss: 0.1617\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1381 - val_loss: 0.1569\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1352 - val_loss: 0.1681\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1325 - val_loss: 0.1616\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1296 - val_loss: 0.1611\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1269 - val_loss: 0.1620\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1246 - val_loss: 0.1588\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1222 - val_loss: 0.1590\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1201 - val_loss: 0.1589\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1180 - val_loss: 0.1666\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1163 - val_loss: 0.1585\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1148 - val_loss: 0.1593\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1133 - val_loss: 0.1608\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1119 - val_loss: 0.1615\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1107 - val_loss: 0.1552\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1097 - val_loss: 0.1630\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1086 - val_loss: 0.1548\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1075 - val_loss: 0.1595\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1066 - val_loss: 0.1539\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1055 - val_loss: 0.1568\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1049 - val_loss: 0.1477\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1040 - val_loss: 0.1570\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1034 - val_loss: 0.1507\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1025 - val_loss: 0.1489\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1024 - val_loss: 0.1569\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1015 - val_loss: 0.1517\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1009 - val_loss: 0.1572\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1005 - val_loss: 0.1445\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0996 - val_loss: 0.1469\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0994 - val_loss: 0.1463\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0986 - val_loss: 0.1495\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0983 - val_loss: 0.1465\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0977 - val_loss: 0.1509\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0975 - val_loss: 0.1418\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0967 - val_loss: 0.1464\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0965 - val_loss: 0.1449\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0961 - val_loss: 0.1456\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0958 - val_loss: 0.1500\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0954 - val_loss: 0.1472\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0953 - val_loss: 0.1465\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0949 - val_loss: 0.1478\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0944 - val_loss: 0.1486\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0942 - val_loss: 0.1493\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0939 - val_loss: 0.1443\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0933 - val_loss: 0.1427\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0934 - val_loss: 0.1456\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0930 - val_loss: 0.1401\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0929 - val_loss: 0.1446\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0925 - val_loss: 0.1412\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0921 - val_loss: 0.1431\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0922 - val_loss: 0.1403\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0918 - val_loss: 0.1385\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0915 - val_loss: 0.1402\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0914 - val_loss: 0.1401\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0912 - val_loss: 0.1466\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0907 - val_loss: 0.1391\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0907 - val_loss: 0.1396\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0903 - val_loss: 0.1409\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0901 - val_loss: 0.1428\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0901 - val_loss: 0.1419\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0899 - val_loss: 0.1415\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0897 - val_loss: 0.1361\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0896 - val_loss: 0.1446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc359276950>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(512, activation='relu')(input_img)\n",
    "encoded = Dense(256, activation='relu')(encoded)\n",
    "encoded = Dense(128, activation='relu')(encoded)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(256, activation='relu')(decoded)\n",
    "decoded = Dense(512, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAzzEAQAAAAAAyAAPcQAAAAAAADLw/xMs8TjMSLJxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3e7111d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = autoencoder.predict(x_test)\n",
    "decoded_imgs = autoencoder.predict(encoded_imgs)\n",
    "\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[1841 1387 1067]\n",
      " [1549 1179  792]\n",
      " [   0  727 1458]]\n",
      "[1841, 1179, 1458]\n",
      "0.4478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3, n_init=20)\n",
    "y_pred = kmeans.fit_predict((encoded_imgs))\n",
    "print(acc(y_test, y_pred))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3024 - val_loss: 0.2008\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2004 - val_loss: 0.1496\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1683 - val_loss: 0.1418\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1526 - val_loss: 0.1243\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1434 - val_loss: 0.1214\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1365 - val_loss: 0.1145\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1311 - val_loss: 0.1102\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1277 - val_loss: 0.1106\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1241 - val_loss: 0.1113\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1216 - val_loss: 0.1062\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1189 - val_loss: 0.1064\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1176 - val_loss: 0.1036\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1162 - val_loss: 0.1030\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1148 - val_loss: 0.1019\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1136 - val_loss: 0.1015\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1126 - val_loss: 0.1035\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1118 - val_loss: 0.1005\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1114 - val_loss: 0.1020\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1111 - val_loss: 0.0999\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1104 - val_loss: 0.1019\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1099 - val_loss: 0.0975\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1095 - val_loss: 0.1004\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1088 - val_loss: 0.0977\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1085 - val_loss: 0.0993\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1080 - val_loss: 0.0974\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1074 - val_loss: 0.0986\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1070 - val_loss: 0.1002\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1062 - val_loss: 0.0973\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1063 - val_loss: 0.0954\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1058 - val_loss: 0.0973\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1056 - val_loss: 0.0944\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1055 - val_loss: 0.0976\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1050 - val_loss: 0.0943\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1049 - val_loss: 0.0979\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1038 - val_loss: 0.0936\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1040 - val_loss: 0.0941\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1040 - val_loss: 0.0932\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1037 - val_loss: 0.0943\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1036 - val_loss: 0.0937\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1031 - val_loss: 0.0971\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1033 - val_loss: 0.0920\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1029 - val_loss: 0.0935\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1023 - val_loss: 0.0954\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1022 - val_loss: 0.0924\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1020 - val_loss: 0.0954\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1020 - val_loss: 0.0914\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1020 - val_loss: 0.0926\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1020 - val_loss: 0.0923\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1020 - val_loss: 0.0947\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1016 - val_loss: 0.0920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc3bc030110>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAIAM+P8gSdPmYC9/6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc330acef10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = autoencoder.predict(x_test)\n",
    "decoded_imgs = autoencoder.predict(encoded_imgs)\n",
    "\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = np.reshape(encoded_imgs, (len(x_test), 28*28*1))  # adapt this if using `channels_first` image data format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 5.5 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "kmeans = KMeans(n_clusters=3, n_init=20)\n",
    "y_pred = kmeans.fit_predict((encoded_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[   0  790 1497]\n",
      " [1808 1269 1097]\n",
      " [1582 1234  723]]\n",
      "[1497, 1808, 1234]\n",
      "0.4539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(acc(y_test, y_pred))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), 28*28*1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28*28*1))  # adapt this if using `channels_first` image data format\n",
    "est = KMeans(n_clusters=3, n_jobs=20)\n",
    "y_pred = est.fit(x_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[ 458  559 1427]\n",
      " [ 282  918  675]\n",
      " [2650 1816 1215]]\n",
      "[1427, 918, 2650]\n",
      "0.4995\n"
     ]
    }
   ],
   "source": [
    "print(acc(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 4.83 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pca = PCA(n_components=3).fit(x_train)\n",
    "est = KMeans(init=pca.components_, n_clusters=3, n_init=20)\n",
    "y_pred = est.fit(x_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[ 458  559 1427]\n",
      " [2650 1816 1215]\n",
      " [ 282  918  675]]\n",
      "[1427, 2650, 918]\n",
      "0.4995\n"
     ]
    }
   ],
   "source": [
    "print(acc(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing PCA would improve performance by 12.18\n"
     ]
    }
   ],
   "source": [
    "print \"Doing PCA would improve performance by\", np.round(((5.5-4.83)/5.5)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fc2e7852450>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
